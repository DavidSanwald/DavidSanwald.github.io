<!DOCTYPE html>
<html class="no-js">
  <head>
	<meta charset="utf-8">
	<title>Cynical Reinforcement Learning | random walks and lots of &#9829;s</title>
	<meta name="description" content="Sometimes the world of reinforcement learning is so dark and cynical.Gridworlds like the one I plottet below are utilized to experiment and explore different...">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-Frame-Options" content="sameorigin">

	<!-- CSS -->
	<link rel="stylesheet" href="/css/main.css">

	<!--Favicon-->
	<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">

	<!-- Canonical -->
	<link rel="canonical" href="https://davidsanwald.github.io/2016/08/10/cynical-RL.html">

	<!-- RSS -->
	<link rel="alternate" type="application/atom+xml" title="random walks and lots of &#9829;s" href="https://davidsanwald.github.io/feed.xml" />

	<!-- Font Awesome -->
	<link href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet">

	<!-- Google Fonts -->
	
	<link href="//fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,700italic,400italic" rel="stylesheet" type="text/css">
	

	<!-- KaTeX -->
	
	<script type="text/javascript" async
	  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
	</script>
	

	<!-- Google Analytics -->
	
<!-- Begin Jekyll SEO tag v2.0.0 -->
<title>Cynical Reinforcement Learning</title>
<meta property="og:title" content="Cynical Reinforcement Learning" />
<meta name="description" content="Sometimes the world of reinforcement learning is so dark and cynical.Gridworlds like the one I plottet below are utilized to experiment and explore different core characteristics of learning agents.Unfortunately they aren’t as popular as they have been as a research tool (this paper shows that gridworlds still are very relevant) they are still omnipresent in teaching because they have so small discrete state spaces and actual humans can actually understand the state representations (mostly just xy coordinates on a grid).The example below  has the following rules(taken from the excellent Sutton and Barto’s amazing book on RL)." />
<meta property="og:description" content="Sometimes the world of reinforcement learning is so dark and cynical.Gridworlds like the one I plottet below are utilized to experiment and explore different core characteristics of learning agents.Unfortunately they aren’t as popular as they have been as a research tool (this paper shows that gridworlds still are very relevant) they are still omnipresent in teaching because they have so small discrete state spaces and actual humans can actually understand the state representations (mostly just xy coordinates on a grid).The example below  has the following rules(taken from the excellent Sutton and Barto’s amazing book on RL)." />
<link rel="canonical" href="https://davidsanwald.github.io/2016/08/10/cynical-RL.html" />
<meta property="og:url" content="https://davidsanwald.github.io/2016/08/10/cynical-RL.html" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2016-08-10T00:00:00+00:00" />
<script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "headline": "Cynical Reinforcement Learning",
    "datePublished": "2016-08-10T00:00:00+00:00",
    "description": "Sometimes the world of reinforcement learning is so dark and cynical.Gridworlds like the one I plottet below are utilized to experiment and explore different core characteristics of learning agents.Unfortunately they aren’t as popular as they have been as a research tool (this paper shows that gridworlds still are very relevant) they are still omnipresent in teaching because they have so small discrete state spaces and actual humans can actually understand the state representations (mostly just xy coordinates on a grid).The example below  has the following rules(taken from the excellent Sutton and Barto’s amazing book on RL).",
    "url": "https://davidsanwald.github.io/2016/08/10/cynical-RL.html"
  }
</script>
<!-- End Jekyll SEO tag -->
</head>

  <body>
    <header class="site-header">
	<div class="branding">
		
		<a href="/">
			<img class="avatar" src="/img/avatar.png" alt=""/>
		</a>
		
		<h1 class="site-title">
			<a href="/">random walks and lots of &#9829;s</a>
		</h1>
	</div>
	<nav class="site-nav">
		<ul>
			
			
			
			
			<li>
				<a class="page-link" href="/about/">
					About
				</a>
			</li>
			
			
			
			
			
			
			
			
			
			
			
			
			<!-- Social icons from Font Awesome, if enabled -->
			


<li>
	<a href="mailto:why.ever.not.berlin@gmail.com" title="Email">
		<i class="fa fa-fw fa-envelope"></i>
	</a>
</li>













<li>
	<a href="https://github.com/DavidSanwald" title="Follow on GitHub">
		<i class="fa fa-fw fa-github"></i>
	</a>
</li>





















<li>
	<a href="https://twitter.com/DavidSanwald" title="Follow on Twitter">
		<i class="fa fa-fw fa-twitter"></i>
	</a>
</li>






		</ul>
	</nav>
</header>

    <div class="content">
      <article >
  <header style="background-image: url('/')">
    <h1 class="title">Cynical Reinforcement Learning</h1>
    <p class="subtitle"> </p>
    <p class="meta">
    August 10, 2016
    
    </p>
  </header>
  <section class="post-content"><ul>
  <li>The agent starts in the top left corner.</li>
  <li>Each step gets an negative reward of <strong>-1</strong></li>
  <li>If the agent steps on one of the magenta cliff tiles on the top, there is a negative reward of <strong>-100</strong> for falling off the cliff and the agent has to start again from the top left corner.</li>
  <li>The goal is to reach the top right corner. When reaching the top right corner, everything starts all over again.</li>
</ul>

<p><img src="/img/cliff_map.png" alt="A world of pain and suffering!!" /></p>

<p>Sometimes it strikes me how dark, twisted and cynical this is, even though it’s just a toy example. Basically it states</p>

<ul>
  <li><strong>-1</strong> for every step you make means nothing less than <strong>living is suffering</strong></li>
  <li>Even if you reach your goal you don’t get any reward, just you’re suffering ends till it starts all over again. You can’t escape.</li>
  <li>Jumping off the cliff won’t help you. You just have to start over again. There’s no escape.</li>
</ul>

<p>There’s also a much more positive life lesson one could learn from <script type="math/tex">\epsilon</script>-greedy exploration policies. I’ll definitely have to write about it soon, to balance out this post.</p>
</section>
</article>

<!-- Post navigation -->


<!-- Disqus -->

<div class="comments">
  <div id="disqus_thread"></div>
<script type="text/javascript">
	var disqus_shortname = 'random-walks';
	(function() {
		var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
		dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
		(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

</div>


<!-- Muut -->


    </div>
    
<script src="/js/katex_init.js"></script>



<footer class="site-footer">
	<p class="text">&#9829; &#9829; &#9829;  to  <a href="https://rohanchandra.github.io/project/type/">Type Theme</a>
</p>
</footer>


  </body>
</html>
